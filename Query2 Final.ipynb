{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bb5f334-3bb9-487d-953d-ca9fa65a626f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+------------------+---+\n",
      "|year|   precinct|  closed_case_rate|  #|\n",
      "+----+-----------+------------------+---+\n",
      "|2010|    Rampart| 32.84713448949121|  1|\n",
      "|2010|    Olympic|31.515289821999087|  2|\n",
      "|2010|     Harbor| 29.36028339237341|  3|\n",
      "|2011|    Olympic|35.040060090135206|  1|\n",
      "|2011|    Rampart|  32.4964471814306|  2|\n",
      "|2011|     Harbor| 28.51336246316431|  3|\n",
      "|2012|    Olympic| 34.29708533302119|  1|\n",
      "|2012|    Rampart| 32.46000463714352|  2|\n",
      "|2012|     Harbor|29.509585848956675|  3|\n",
      "|2013|    Olympic| 33.58217940999398|  1|\n",
      "|2013|    Rampart|  32.1060382916053|  2|\n",
      "|2013|     Harbor|29.723638951488557|  3|\n",
      "|2014|   Van Nuys|  32.0215235281705|  1|\n",
      "|2014|West Valley| 31.49754809505847|  2|\n",
      "|2014|    Mission|31.224939855653567|  3|\n",
      "|2015|   Van Nuys|32.265140677157845|  1|\n",
      "|2015|    Mission|30.463762673676303|  2|\n",
      "|2015|   Foothill|30.353001803658852|  3|\n",
      "|2016|   Van Nuys|32.194518462124094|  1|\n",
      "|2016|West Valley| 31.40146437042384|  2|\n",
      "+----+-----------+------------------+---+\n",
      "only showing top 20 rows\n",
      "\n",
      "Time taken: 22.20 seconds"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructField, StructType, IntegerType, StringType\n",
    "from pyspark.sql.functions import col, when, count, to_timestamp, year\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "import time\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Query 2 with Dataframe\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"dr_no\", IntegerType(), True),\n",
    "    StructField(\"date_rptd\", StringType(), True),\n",
    "    StructField(\"date_occ\", StringType(), True),\n",
    "    StructField(\"time_occ\", StringType(), True),\n",
    "    StructField(\"area\", StringType(), True),\n",
    "    StructField(\"area_name\", StringType(), True),\n",
    "    StructField(\"rpt_dist_no\", StringType(), True),\n",
    "    StructField(\"part_1_2\", IntegerType(), True),\n",
    "    StructField(\"crm_cd\", StringType(), True),\n",
    "    StructField(\"crm_cd_desc\", StringType(), True),\n",
    "    StructField(\"mocodes\", StringType(), True),\n",
    "    StructField(\"vict_age\", StringType(), True),\n",
    "    StructField(\"vict_sex\", StringType(), True),\n",
    "    StructField(\"vict_descent\", StringType(), True),\n",
    "    StructField(\"premis_cd\", StringType(), True),\n",
    "    StructField(\"premis_desc\", StringType(), True),\n",
    "    StructField(\"weapon_used_cd\", StringType(), True),\n",
    "    StructField(\"weapon_desc\", StringType(), True),\n",
    "    StructField(\"status\", StringType(), True),\n",
    "    StructField(\"status_desc\", StringType(), True),\n",
    "    StructField(\"crm_cd_1\", StringType(), True),\n",
    "    StructField(\"crm_cd_2\", StringType(), True),\n",
    "    StructField(\"crm_cd_3\", StringType(), True),\n",
    "    StructField(\"crm_cd_4\", StringType(), True),\n",
    "    StructField(\"location\", StringType(), True),\n",
    "    StructField(\"cross_street\", StringType(), True),\n",
    "    StructField(\"lat\", IntegerType(), True),\n",
    "    StructField(\"lon\", IntegerType(), True),\n",
    "])\n",
    "\n",
    "file_1 = \"s3://initial-notebook-data-bucket-dblab-905418150721/\\\n",
    "CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\"\n",
    "file_2 = \"s3://initial-notebook-data-bucket-dblab-905418150721/\\\n",
    "CrimeData/Crime_Data_from_2020_to_Present_20241101.csv\"\n",
    "df1 = spark.read.csv(file_1, header=True, schema=schema)\n",
    "df2 = spark.read.csv(file_2, header=True, schema=schema)\n",
    "df = df1.union(df2)\n",
    "# Δημιουργουμε νεα στηλη που θα δηλωνει το αν εχει κλεισει η υποθεση\n",
    "# ή οχι, βασει του αν υπαρχει το Invest Cont ή UNK στην στηλη case_status\n",
    "df = df.withColumn(\n",
    "    \"case_status\",\n",
    "    when(col(\"status_desc\").isin(\"UNK\", \"Invest Cont\"), \"Case not closed\")\n",
    "    .otherwise(\"Case closed\")\n",
    ")\n",
    "# Κραταμε τις στηλες που μας ενδιαφερουν\n",
    "df = df.select(\"date_occ\", \"area_name\", \"case_status\")\n",
    "# Δημιουργουμε στηλη με συγκεκριμενο φορματ με τις ημερομηνιες του συμβαντος\n",
    "df = df.withColumn(\"date\", to_timestamp(col(\"date_occ\"),\n",
    "                                        \"MM/dd/yyyy hh:mm:ss a\"))\n",
    "# για να παρουμε την χρονολογια απο καθε υποθεση\n",
    "df = df.withColumn(\"year\", year(col(\"date\")))\n",
    "df = df.select(\"year\", \"area_name\", \"case_status\")\n",
    "# Υπολογιζουμε το συνολικο αριθμο υποθεσεων και των περατωμενων υποθεσεων\n",
    "# ανα περιοχη και ετος\n",
    "df_stats = df.groupBy(\"year\", \"area_name\").agg(\n",
    "    count(\"*\").alias(\"total_cases\"),\n",
    "    count(when(col(\"case_status\") == \"Case closed\", 1)).alias(\"closed_cases\")\n",
    ")\n",
    "# Υπολογιζουμε το ποσοστο περατωμενων υποθεσεων\n",
    "df_stats = df_stats.withColumn(\"closed_case_rate\",\n",
    "                               (col(\"closed_cases\") / col(\"total_cases\"))*100)\n",
    "# Δημιουργουμε παραθυρο για καταταξη ανα ετος και ποσοστο κλεισμενων υποθεσεων\n",
    "window_spec = Window.partitionBy(\"year\")\\\n",
    "            .orderBy(col(\"closed_case_rate\").desc())\n",
    "# Υπολογιζουμε της καταταξης\n",
    "df_stats = df_stats.withColumn(\"#\", F.rank().over(window_spec))\n",
    "# Επιλεγουμε τις 3 πρωτες περιοχες για καθε ετος\n",
    "df_top_3 = df_stats.filter(col(\"#\") <= 3)\n",
    "df_top_3 = df_top_3.select(\"year\", \"area_name\", \"closed_case_rate\", \"#\")\n",
    "df_top_3 = df_top_3.withColumnRenamed(\"area_name\", \"precinct\")\n",
    "# Ταξινομουμε τα αποτελεσματα κατα ετος και καταταξη και τα εμφανιζουμε\n",
    "df_top_3.orderBy(\"year\", \"#\").show()\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9bcd499-3979-4c2f-afc2-151194490be6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+------------------+---+\n",
      "|year|   precinct|  closed_case_rate|  #|\n",
      "+----+-----------+------------------+---+\n",
      "|2010|    Rampart| 32.84713448949121|  1|\n",
      "|2010|    Olympic|31.515289821999087|  2|\n",
      "|2010|     Harbor| 29.36028339237341|  3|\n",
      "|2011|    Olympic|35.040060090135206|  1|\n",
      "|2011|    Rampart|  32.4964471814306|  2|\n",
      "|2011|     Harbor| 28.51336246316431|  3|\n",
      "|2012|    Olympic| 34.29708533302119|  1|\n",
      "|2012|    Rampart| 32.46000463714352|  2|\n",
      "|2012|     Harbor|29.509585848956675|  3|\n",
      "|2013|    Olympic| 33.58217940999398|  1|\n",
      "|2013|    Rampart|  32.1060382916053|  2|\n",
      "|2013|     Harbor|29.723638951488557|  3|\n",
      "|2014|   Van Nuys|  32.0215235281705|  1|\n",
      "|2014|West Valley| 31.49754809505847|  2|\n",
      "|2014|    Mission|31.224939855653567|  3|\n",
      "|2015|   Van Nuys|32.265140677157845|  1|\n",
      "|2015|    Mission|30.463762673676303|  2|\n",
      "|2015|   Foothill|30.353001803658852|  3|\n",
      "|2016|   Van Nuys|32.194518462124094|  1|\n",
      "|2016|West Valley| 31.40146437042384|  2|\n",
      "+----+-----------+------------------+---+\n",
      "only showing top 20 rows\n",
      "\n",
      "Time taken: 18.74 seconds"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Query 2 with SQL\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"dr_no\", IntegerType(), True),\n",
    "    StructField(\"date_rptd\", StringType(), True),\n",
    "    StructField(\"date_occ\", StringType(), True),\n",
    "    StructField(\"time_occ\", StringType(), True),\n",
    "    StructField(\"area\", StringType(), True),\n",
    "    StructField(\"area_name\", StringType(), True),\n",
    "    StructField(\"rpt_dist_no\", StringType(), True),\n",
    "    StructField(\"part_1_2\", IntegerType(), True),\n",
    "    StructField(\"crm_cd\", StringType(), True),\n",
    "    StructField(\"crm_cd_desc\", StringType(), True),\n",
    "    StructField(\"mocodes\", StringType(), True),\n",
    "    StructField(\"vict_age\", StringType(), True),\n",
    "    StructField(\"vict_sex\", StringType(), True),\n",
    "    StructField(\"vict_descent\", StringType(), True),\n",
    "    StructField(\"premis_cd\", StringType(), True),\n",
    "    StructField(\"premis_desc\", StringType(), True),\n",
    "    StructField(\"weapon_used_cd\", StringType(), True),\n",
    "    StructField(\"weapon_desc\", StringType(), True),\n",
    "    StructField(\"status\", StringType(), True),\n",
    "    StructField(\"status_desc\", StringType(), True),\n",
    "    StructField(\"crm_cd_1\", StringType(), True),\n",
    "    StructField(\"crm_cd_2\", StringType(), True),\n",
    "    StructField(\"crm_cd_3\", StringType(), True),\n",
    "    StructField(\"crm_cd_4\", StringType(), True),\n",
    "    StructField(\"location\", StringType(), True),\n",
    "    StructField(\"cross_street\", StringType(), True),\n",
    "    StructField(\"lat\", IntegerType(), True),\n",
    "    StructField(\"lon\", IntegerType(), True),\n",
    "])\n",
    "\n",
    "file_1 = \"s3://initial-notebook-data-bucket-dblab-905418150721/\\\n",
    "CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\"\n",
    "file_2 = \"s3://initial-notebook-data-bucket-dblab-905418150721/\\\n",
    "CrimeData/Crime_Data_from_2020_to_Present_20241101.csv\"\n",
    "df1 = spark.read.csv(file_1, header=True, schema=schema)\n",
    "df2 = spark.read.csv(file_2, header=True, schema=schema)\n",
    "df = df1.union(df2)\n",
    "# Δημιουργουμε εναν προσωρινο πινακα που θα χρησιμοποιησουμε\n",
    "# στο πρωτο SQL query\n",
    "df.createOrReplaceTempView(\"crime_data\")\n",
    "# Εκτελουμε SQL Query για τον υπολογισμο του case_status\n",
    "query_case_status = \"\"\"\n",
    "    SELECT\n",
    "        to_timestamp(date_occ, 'MM/dd/yyyy hh:mm:ss a') AS date,\n",
    "        area_name,\n",
    "        CASE\n",
    "            WHEN status_desc IN ('UNK', 'Invest Cont') THEN 'Case not closed'\n",
    "            ELSE 'Case closed'\n",
    "        END AS case_status\n",
    "    FROM crime_data\n",
    "\"\"\"\n",
    "df_case_status = spark.sql(query_case_status)\n",
    "# Δημιουργουμε προσωρινο πινακα για τα αποτελεσματα με case_status\n",
    "df_case_status.createOrReplaceTempView(\"case_status_data\")\n",
    "# Εκτελουμε SQL query για υπολογισμο των στατιστικων\n",
    "query_stats = \"\"\"\n",
    "    SELECT \n",
    "        YEAR(date) AS year,\n",
    "        area_name,\n",
    "        COUNT(*) AS total_cases,\n",
    "        COUNT(CASE WHEN case_status = 'Case closed' THEN 1 END) AS closed_cases\n",
    "    FROM case_status_data\n",
    "    GROUP BY year, area_name\n",
    "\"\"\"\n",
    "df_stats = spark.sql(query_stats)\n",
    "# Υπολογιζουμε ποσοστο κλεισμενων υποθεσεων\n",
    "df_stats.createOrReplaceTempView(\"stats_data\")\n",
    "# Εκτελουμε SQL query για υπολογισμο ποσοστου και καταταξης\n",
    "query_final = \"\"\"\n",
    "    SELECT\n",
    "        year,\n",
    "        area_name,\n",
    "        closed_cases / total_cases * 100 AS closed_case_rate,\n",
    "        RANK() OVER (PARTITION BY year ORDER BY closed_cases\n",
    "        / total_cases * 100 DESC) AS rank\n",
    "    FROM stats_data\n",
    "\"\"\"\n",
    "df_final = spark.sql(query_final)\n",
    "# Επιλεγουμε τις 3 πρωτες περιοχες για καθε ετος\n",
    "df_top_3 = df_final.filter(col(\"rank\") <= 3)\n",
    "# Επιλεγουμε τις επιθυμητες στηλες και αλλαζουμε ονομα στο επιθυμητο\n",
    "df_top_3 = df_top_3.select(\"year\", \"area_name\", \"closed_case_rate\", \"rank\")\n",
    "df_top_3 = df_top_3.withColumnRenamed(\"area_name\", \"precinct\")\n",
    "df_top_3 = df_top_3.withColumnRenamed(\"rank\", \"#\")\n",
    "# Ταξινομουμε τα αποτελεσματα κατα ετος και καταταξη και τα εμφανιζουμε\n",
    "df_top_3.orderBy(\"year\", \"rank\").show()\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eb45e20-66ab-4569-a0fd-74170bc8872c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done"
     ]
    }
   ],
   "source": [
    "# Ακολουθει κωδικας για την μετατροπη ενος αρχειο CSV σε αρχειο Parquet\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"CSV to Parquet Conversion\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "file_1 = \"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\"\n",
    "file_2 = \"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv\"\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"dr_no\", IntegerType(), True),\n",
    "    StructField(\"date_rptd\", StringType(), True),\n",
    "    StructField(\"date_occ\", StringType(), True),\n",
    "    StructField(\"time_occ\", StringType(), True),\n",
    "    StructField(\"area\", StringType(), True),\n",
    "    StructField(\"area_name\", StringType(), True),\n",
    "    StructField(\"rpt_dist_no\", StringType(), True),\n",
    "    StructField(\"part_1_2\", IntegerType(), True),\n",
    "    StructField(\"crm_cd\", StringType(), True),\n",
    "    StructField(\"crm_cd_desc\", StringType(), True),\n",
    "    StructField(\"mocodes\", StringType(), True),\n",
    "    StructField(\"vict_age\", StringType(), True),\n",
    "    StructField(\"vict_sex\", StringType(), True),\n",
    "    StructField(\"vict_descent\", StringType(), True),\n",
    "    StructField(\"premis_cd\", StringType(), True),\n",
    "    StructField(\"premis_desc\", StringType(), True),\n",
    "    StructField(\"weapon_used_cd\", StringType(), True),\n",
    "    StructField(\"weapon_desc\", StringType(), True),\n",
    "    StructField(\"status\", StringType(), True),\n",
    "    StructField(\"status_desc\", StringType(), True),\n",
    "    StructField(\"crm_cd_1\", StringType(), True),\n",
    "    StructField(\"crm_cd_2\", StringType(), True),\n",
    "    StructField(\"crm_cd_3\", StringType(), True),\n",
    "    StructField(\"crm_cd_4\", StringType(), True),\n",
    "    StructField(\"location\", StringType(), True),\n",
    "    StructField(\"cross_street\", StringType(), True),\n",
    "    StructField(\"lat\", IntegerType(), True),\n",
    "    StructField(\"lon\", IntegerType(), True),\n",
    "])\n",
    "\n",
    "df1 = spark.read.csv(file_1, header=True, schema=schema)\n",
    "df2 = spark.read.csv(file_2, header=True, schema=schema)\n",
    "df = df1.union(df2)\n",
    "\n",
    "# Διαδρομη αποθηκευσης του αρχειου Parquet στο S3\n",
    "output_path = \"s3://groups-bucket-dblab-905418150721/group25/Outputs\"\n",
    "\n",
    "# Αποθήκευση σε Parquet format\n",
    "# Με το mode=\"overwrite\" διασφαλιζουμε οτι αν υπαρχει ηδη αρχείο\n",
    "# θα αντικατασταθεί\n",
    "df.write.mode(\"overwrite\").parquet(output_path)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f307f0ca-fcf3-4947-87b8-e0d2b0cf4012",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+------------------+---+\n",
      "|year|   precinct|  closed_case_rate|  #|\n",
      "+----+-----------+------------------+---+\n",
      "|2010|    Rampart| 32.84713448949121|  1|\n",
      "|2010|    Olympic|31.515289821999087|  2|\n",
      "|2010|     Harbor| 29.36028339237341|  3|\n",
      "|2011|    Olympic|35.040060090135206|  1|\n",
      "|2011|    Rampart|  32.4964471814306|  2|\n",
      "|2011|     Harbor| 28.51336246316431|  3|\n",
      "|2012|    Olympic| 34.29708533302119|  1|\n",
      "|2012|    Rampart| 32.46000463714352|  2|\n",
      "|2012|     Harbor|29.509585848956675|  3|\n",
      "|2013|    Olympic| 33.58217940999398|  1|\n",
      "|2013|    Rampart|  32.1060382916053|  2|\n",
      "|2013|     Harbor|29.723638951488557|  3|\n",
      "|2014|   Van Nuys|  32.0215235281705|  1|\n",
      "|2014|West Valley| 31.49754809505847|  2|\n",
      "|2014|    Mission|31.224939855653567|  3|\n",
      "|2015|   Van Nuys|32.265140677157845|  1|\n",
      "|2015|    Mission|30.463762673676303|  2|\n",
      "|2015|   Foothill|30.353001803658852|  3|\n",
      "|2016|   Van Nuys|32.194518462124094|  1|\n",
      "|2016|West Valley| 31.40146437042384|  2|\n",
      "+----+-----------+------------------+---+\n",
      "only showing top 20 rows\n",
      "\n",
      "Time taken: 3.48 seconds"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Query 2 with Parquet\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Διαδρομη του Parquet φακελου\n",
    "parquet_path = \"s3://groups-bucket-dblab-905418150721/group25/Outputs/\"\n",
    "\n",
    "# Φορτωση δεδομενων από το Parquet\n",
    "df = spark.read.parquet(parquet_path)\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"case_status\",\n",
    "    when(col(\"status_desc\").isin(\"UNK\", \"Invest Cont\"), \"Case not closed\")\n",
    "    .otherwise(\"Case closed\")\n",
    ")\n",
    "\n",
    "df = df.select(\"date_occ\", \"area_name\", \"case_status\")\n",
    "df = df.withColumn(\"date\", to_timestamp(col(\"date_occ\"), \"MM/dd/yyyy hh:mm:ss a\"))\n",
    "df = df.withColumn(\"year\", year(col(\"date\")))\n",
    "df = df.select(\"year\", \"area_name\", \"case_status\")\n",
    "\n",
    "\n",
    "df_stats = df.groupBy(\"year\", \"area_name\").agg(\n",
    "    count(\"*\").alias(\"total_cases\"),\n",
    "    count(when(col(\"case_status\") == \"Case closed\", 1)).alias(\"closed_cases\")\n",
    ")\n",
    "\n",
    "df_stats = df_stats.withColumn(\"closed_case_rate\",\n",
    "                               (col(\"closed_cases\")/col(\"total_cases\"))*100)\n",
    "\n",
    "\n",
    "window_spec = Window.partitionBy(\"year\")\\\n",
    "                .orderBy(col(\"closed_case_rate\").desc())\n",
    "\n",
    "df_stats = df_stats.withColumn(\"#\", F.rank().over(window_spec))\n",
    "\n",
    "df_top_3 = df_stats.filter(col(\"#\") <= 3)\n",
    "\n",
    "df_top_3 = df_top_3.select(\"year\", \"area_name\", \"closed_case_rate\", \"#\")\n",
    "df_top_3 = df_top_3.withColumnRenamed(\"area_name\", \"precinct\")\n",
    "\n",
    "df_top_3.orderBy(\"year\", \"#\").show()\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
